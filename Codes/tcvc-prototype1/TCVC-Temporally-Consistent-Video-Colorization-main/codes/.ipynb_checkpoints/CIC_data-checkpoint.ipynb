{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import color\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread\n",
    "import numpy as np\n",
    "import os\n",
    "import sklearn.neighbors as nn\n",
    "import warnings\n",
    "import configparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNEncode():\n",
    "    ''' Encode points using NN search and Gaussian kernel '''\n",
    "    def __init__(self,NN,sigma,km_filepath='',cc=-1):\n",
    "        if(check_value(cc,-1)):\n",
    "            self.cc = np.load(km_filepath)\n",
    "        else:\n",
    "            self.cc = cc\n",
    "        self.K = self.cc.shape[0]\n",
    "        self.NN = int(NN)\n",
    "        self.sigma = sigma\n",
    "        self.nbrs = nn.NearestNeighbors(n_neighbors=NN, algorithm='ball_tree').fit(self.cc)\n",
    "\n",
    "        self.alreadyUsed = False\n",
    "\n",
    "    def encode_points_mtx_nd(self,pts_nd,axis=1,returnSparse=False,sameBlock=True):\n",
    "\n",
    "        pts_flt = flatten_nd_array(pts_nd,axis=axis)\n",
    "\n",
    "        P = pts_flt.shape[0]\n",
    "        if(sameBlock and self.alreadyUsed):\n",
    "            self.pts_enc_flt[...] = 0 # already pre-allocated\n",
    "        else:\n",
    "            self.alreadyUsed = True\n",
    "            self.pts_enc_flt = np.zeros((P,self.K))\n",
    "            self.p_inds = np.arange(0,P,dtype='int')[:,na()]\n",
    "\n",
    "        P = pts_flt.shape[0]\n",
    "\n",
    "        (dists,inds) = self.nbrs.kneighbors(pts_flt)\n",
    "\n",
    "        wts = np.exp(-dists**2/(2*self.sigma**2))\n",
    "        wts = wts/np.sum(wts,axis=1)[:,na()]\n",
    "\n",
    "        self.pts_enc_flt[self.p_inds,inds] = wts\n",
    "        pts_enc_nd = unflatten_2d_array(self.pts_enc_flt,pts_nd,axis=axis)\n",
    "\n",
    "        return pts_enc_nd\n",
    "\n",
    "    def decode_points_mtx_nd(self,pts_enc_nd,axis=1):\n",
    "        pts_enc_flt = flatten_nd_array(pts_enc_nd,axis=axis)\n",
    "        pts_dec_flt = np.dot(pts_enc_flt,self.cc)\n",
    "        pts_dec_nd = unflatten_2d_array(pts_dec_flt,pts_enc_nd,axis=axis)\n",
    "        return pts_dec_nd\n",
    "\n",
    "    def decode_1hot_mtx_nd(self,pts_enc_nd,axis=1,returnEncode=False):\n",
    "        pts_1hot_nd = nd_argmax_1hot(pts_enc_nd,axis=axis)\n",
    "        pts_dec_nd = self.decode_points_mtx_nd(pts_1hot_nd,axis=axis)\n",
    "        if(returnEncode):\n",
    "            return (pts_dec_nd,pts_1hot_nd)\n",
    "        else:\n",
    "            return pts_dec_nd\n",
    "\n",
    "def _nnencode(data_ab_ss):\n",
    "    '''Encode to 313bin\n",
    "    Args:\n",
    "    data_ab_ss: [N, H, W, 2]\n",
    "    Returns:\n",
    "    gt_ab_313 : [N, H, W, 313]\n",
    "    '''\n",
    "    NN = 10.0\n",
    "    sigma = 5.0\n",
    "    enc_dir = './resources/'\n",
    "    data_ab_ss = np.transpose(data_ab_ss, (0, 3, 1, 2))\n",
    "    nnenc = NNEncode(NN, sigma, km_filepath=os.path.join(enc_dir, 'pts_in_hull.npy'))\n",
    "    gt_ab_313 = nnenc.encode_points_mtx_nd(data_ab_ss, axis=1)\n",
    "\n",
    "    gt_ab_313 = np.transpose(gt_ab_313, (0, 2, 3, 1))\n",
    "    return gt_ab_313"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    '''Preprocess\n",
    "    Args: \n",
    "    data: RGB batch (N * H * W * 3)\n",
    "    Return:\n",
    "    data_l: L channel batch (N * H * W * 1)\n",
    "    gt_ab_313: ab discrete channel batch (N * H/4 * W/4 * 313)\n",
    "    prior_boost_nongray: (N * H/4 * W/4 * 1) \n",
    "    '''\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    N = data.shape[0]\n",
    "    H = data.shape[1]\n",
    "    W = data.shape[2]\n",
    "\n",
    "    #rgb2lab\n",
    "    img_lab = color.rgb2lab(data)\n",
    "\n",
    "    #slice\n",
    "    #l: [0, 100]\n",
    "    img_l = img_lab[:, :, :, 0:1]\n",
    "    #ab: [-110, 110]\n",
    "    data_ab = img_lab[:, :, :, 1:]\n",
    "\n",
    "    #scale img_l to [-50, 50]\n",
    "    data_l = img_l - 50\n",
    "\n",
    "    #subsample 1/4  (N * H/4 * W/4 * 2)\n",
    "    data_ab_ss = data_ab[:, ::4, ::4, :]\n",
    "\n",
    "    #NonGrayMask {N, 1, 1, 1}\n",
    "    thresh = 5\n",
    "    nongray_mask = (np.sum(np.sum(np.sum(np.abs(data_ab_ss) > thresh, axis=1), axis=1), axis=1) > 0)[:, np.newaxis, np.newaxis, np.newaxis]\n",
    "\n",
    "    #NNEncoder\n",
    "    #gt_ab_313: [N, H/4, W/4, 313]\n",
    "    gt_ab_313 = _nnencode(data_ab_ss)\n",
    "\n",
    "    #Prior_Boost \n",
    "    #prior_boost: [N, 1, H/4, W/4]\n",
    "    prior_boost = _prior_boost(gt_ab_313)\n",
    "\n",
    "    #Eltwise\n",
    "    #prior_boost_nongray: [N, 1, H/4, W/4]\n",
    "    prior_boost_nongray = prior_boost * nongray_mask\n",
    "\n",
    "    return data_l, gt_ab_313, prior_boost_nongray\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.expand_dims(np.max(x, axis=-1), axis=-1))\n",
    "    return e_x / np.expand_dims(e_x.sum(axis=-1), axis=-1) # only difference\n",
    "\n",
    "\n",
    "def decode(data_l, conv8_313, rebalance=1):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    data_l   : [1, height, width, 1]\n",
    "    conv8_313: [1, height/4, width/4, 313]\n",
    "    Returns:\n",
    "    img_rgb  : [height, width, 3]\n",
    "    \"\"\"\n",
    "    data_l = data_l + 50\n",
    "    _, height, width, _ = data_l.shape\n",
    "    data_l = data_l[0, :, :, :]\n",
    "    conv8_313 = conv8_313[0, :, :, :]\n",
    "    enc_dir = './resources'\n",
    "    conv8_313_rh = conv8_313 * rebalance\n",
    "    class8_313_rh = softmax(conv8_313_rh)\n",
    "\n",
    "    cc = np.load(os.path.join(enc_dir, 'pts_in_hull.npy'))\n",
    "\n",
    "    data_ab = np.dot(class8_313_rh, cc)\n",
    "    data_ab = resize(data_ab, (height, width))\n",
    "    img_lab = np.concatenate((data_l, data_ab), axis=-1)\n",
    "    img_rgb = color.lab2rgb(img_lab)\n",
    "\n",
    "    return img_rgb\n",
    "\n",
    "def get_data_l(image_path):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    image_path  \n",
    "    Returns:\n",
    "    data_l \n",
    "    \"\"\"\n",
    "    data = imread(image_path)\n",
    "    data = data[None, :, :, :]\n",
    "    img_lab = color.rgb2lab(data)\n",
    "    img_l = img_lab[:, :, :, 0:1]\n",
    "    data_l = img_l - 50\n",
    "    data_l = data_l.astype(dtype=np.float32)\n",
    "    return data, data_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
