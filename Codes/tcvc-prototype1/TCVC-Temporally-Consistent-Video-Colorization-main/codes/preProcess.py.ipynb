{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bzASBRRX-dy"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from skimage import color\n",
        "\n",
        "# conversion among RGB, LAB, Gray\n",
        "def channel_convert(in_c, tar_type, img_list):\n",
        "    if in_c == 3 and tar_type == 'LAB':  # RGB to Lab\n",
        "        return [color.rgb2lab(img) for img in img_list]\n",
        "    elif in_c == 3 and tar_type == 'RGB':  # Lab to BGR\n",
        "        return [color.lab2rgb(img) for img in img_list]\n",
        "    else:\n",
        "        return img_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yw7DeFAjfaLb"
      },
      "outputs": [],
      "source": [
        "# read image by skimage or from png\n",
        "# return: Numpy int8, HWC, RGB, [0, 255]\n",
        "def read_img(path, size=None):\n",
        "    img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "    if img.ndim == 2:\n",
        "        img = np.expand_dims(img, axis = 2)\n",
        "    elif img.ndim == 3:\n",
        "        img = img[:, :, [2, 1, 0]]\n",
        "        img = img.astype(np.float32)\n",
        "\n",
        "    # some images have 4 channels\n",
        "    if img.shape[2] > 3:\n",
        "        img = img[:, :, :3]\n",
        "    img = cv2.resize(img, (384, 512), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "    return img\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgS8KcQdfcbu"
      },
      "outputs": [],
      "source": [
        "# So, this takes folder name converts them to lab and then return PyTorch tensors containing images stacked on L channel and normal LAB. The tensor is batch, channels, height, width\n",
        "def read_img_lab_seq(folder_name):\n",
        "    img_list = [read_img(v) for v in img_lst[:4]]\n",
        "    img_lab = channel_convert(img_list[0].shape[2], 'lab', img_list)\n",
        "\n",
        "    # extracting L channel. Selects all elements along the first two dimensions (rows and columns) of the image. :1: Selects elements from the beginning (index 0) up to but not including index 1 along the third dimension (channels).\n",
        "    img_l = [v[:, :, :1] for v in img_lab]\n",
        "    # aixs = 0 dimension is often referred to as the batch dimension, as it represents a batch of samples or items. 1st frame, 2nd frame. like that\n",
        "    imgs_l = np.stack(img_l, axis=0)\n",
        "    imgs_lab = np.stack(img_lab, axis=0)\n",
        "\n",
        "    # These lines convert the NumPy arrays imgs_l and imgs_lab into PyTorch tensors. The np.ascontiguousarray function ensures that the data is in a contiguous memory layout, which can improve performance. The np.transpose function rearranges the dimensions of the arrays to (channels, height, width), which is a common format for image data in PyTorch. Finally, the float() method converts the data type to torch.float32.\n",
        "    imgs_l = torch.from_numpy(np.ascontiguousarray(np.transpose(imgs_l, (0, 3, 1, 2)))).float()\n",
        "    imgs_lab = torch.from_numpy(np.ascontiguousarray(np.transpose(imgs_lab, (0, 3, 1, 2)))).float()\n",
        "\n",
        "    return imgs_l, imgs_lab\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uV5IIOcF1HTn"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
